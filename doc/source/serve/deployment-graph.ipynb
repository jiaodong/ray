{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ef8771",
   "metadata": {},
   "source": [
    "\n",
    "(serve-deployment-graph)=\n",
    "\n",
    "# Serve Deployment Graph\n",
    "\n",
    "```{note} \n",
    "Note: This feature is still experimental in Alpha release, some APIs are subject to change.\n",
    "```\n",
    "\n",
    "## General Motivation\n",
    "\n",
    "Production machine learning serving pipelines are getting longer and wider. They often consist of multiple, or even tens of models collectively making a final prediction, such as image / video content classification and tagging, fraud detection pipeline with multiple policies and models, multi-stage ranking and recommendation, etc.\n",
    "\n",
    "Meanwhile, the size of a model is also growing beyond the memory limit of a single machine due to the exponentially growing number of parameters, such as GPT-3, sparse feature embeddings in recsys models such that the ability to do disaggregated and distributed inference is desirable and future proof.\n",
    "\n",
    "We want to leverage the programmable and general purpose distributed computing ability of Ray, double down on its unique strengths (scheduling, communication and shared memory) to facilitate authoring, orchestrating, scaling and deployment of complex serving pipelines under one set of DAG API, so a user can program & test multiple models or multiple shards of a single large model dynamically, deploy to production at scale, and upgrade individually.\n",
    "\n",
    "## Key requirements\n",
    "- Provide the ability to author a DAG of Serve nodes to form a complex inference graph.\n",
    "- Pipeline authoring experience should be fully Python-programmable with support for dynamic selection, control flows, user business logic, etc.\n",
    "- DAG can be instantiated and locally executed using tasks and actors API\n",
    "- DAG can be deployed via declarative and idempotent API, individual nodes can be reconfigured and scaled indepenently.\n",
    "\n",
    "__[Full Ray Enhancement Proposal, REP-001: Serve Pipeline](https://github.com/ray-project/enhancements/blob/main/reps/2022-03-08-serve_pipeline.md)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35319020",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "### Deployment\n",
    "Upgradeable group of actors managed by the Serve controller. Currently the primary API in Ray Serve. At authoring time itâ€™s the class or function under `@serve.deployment` decorator. \n",
    "\n",
    "### Node\n",
    "Smallest unit in a graph, typically an annotated class but can also be a function, backed by a group of actors that are scalable and reconfigurable. \n",
    "\n",
    "### Deployment Graph\n",
    "Collection of nodes that forms a DAG that represents an inference graph for complicated tasks. Ex: ensemble, chaining, dynamic selection. \n",
    "\n",
    "### Bind\n",
    "A graph building API applicable to decorated class or function.  `decorated_class_or_func.bind(*args, **kwargs)` generates an IR node that can be used to build graph, and bound arguments will be applied at execution time, including dynamic user input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2811320",
   "metadata": {},
   "source": [
    "## Simple End to End Example\n",
    "\n",
    "Let's start with a simple DAG with the following attributes where each node is empowered by a __[serve deployment](https://docs.ray.io/en/master/serve/core-apis.html#core-api-deployments)__:\n",
    "\n",
    "- All nodes in the deployment graph naturally forms a DAG structure.\n",
    "- A node could use or call into other nodes in the deployment graph.\n",
    "- Deployment graph has mix of class and function as nodes.\n",
    "- Same input or output can be used in multiple nodes in the DAG.\n",
    "- A node might access partial user input.\n",
    "- Control flow is used where dynamic dispatch happens with respect to input value.\n",
    "- Same class can be constructed, or function bound with different args that generates multiple distinct nodes in DAG.\n",
    "- A node can be called either sync or async."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b755e4f",
   "metadata": {},
   "source": [
    "![deployment graph](https://github.com/ray-project/images/blob/master/docs/serve/deployment_graph.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d931c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "from ray.serve.pipeline.generate import DeploymentNameGenerator\n",
    "\n",
    "if ray.is_initialized():\n",
    "    serve.shutdown()\n",
    "    DeploymentNameGenerator.reset()\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(num_cpus=16)\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a721c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import requests\n",
    "import starlette\n",
    "\n",
    "from ray.experimental.dag.input_node import InputNode\n",
    "\n",
    "@serve.deployment\n",
    "async def preprocessor(input_data: str):\n",
    "    \"\"\"Simple feature processing that converts str to int\"\"\"\n",
    "    time.sleep(0.1) # Manual delay for blocking computation\n",
    "    return int(input_data)\n",
    "\n",
    "@serve.deployment\n",
    "async def avg_preprocessor(input_data):\n",
    "    \"\"\"Simple feature processing that returns average of input list as float.\"\"\"\n",
    "    time.sleep(0.15) # Manual delay for blocking computation\n",
    "    return sum(input_data) / len(input_data)\n",
    "\n",
    "@serve.deployment\n",
    "class Model:\n",
    "    def __init__(self, weight: int):\n",
    "        self.weight = weight\n",
    "\n",
    "    async def forward(self, input: int):\n",
    "        time.sleep(0.3) # Manual delay for blocking computation \n",
    "        return f\"({self.weight} * {input})\"\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "class Combiner:\n",
    "    def __init__(self, m1: Model, m2: Model):\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "\n",
    "    async def run(self, req_part_1, req_part_2, operation):\n",
    "        # Merge model input from two preprocessors  \n",
    "        req = f\"({req_part_1} + {req_part_2})\"\n",
    "        \n",
    "        # Submit to both m1 and m2 with same req data in parallel\n",
    "        r1_ref = self.m1.forward.remote(req)\n",
    "        r2_ref = self.m2.forward.remote(req)\n",
    "        \n",
    "        # Async gathering of model forward results for same request data\n",
    "        rst = await asyncio.gather(*[r1_ref, r2_ref])\n",
    "        \n",
    "        # Control flow that determines runtime behavior based on user input\n",
    "        if operation == \"sum\":\n",
    "            return f\"sum({rst})\"\n",
    "        else:\n",
    "            return f\"max({rst})\"\n",
    "        \n",
    "@serve.deployment\n",
    "class DAGDriver:\n",
    "    def __init__(self, dag_handle):\n",
    "        self.dag_handle = dag_handle\n",
    "\n",
    "    async def predict(self, inp):\n",
    "        \"\"\"Perform inference directly without HTTP.\"\"\"\n",
    "        return await self.dag_handle.remote(inp)\n",
    "\n",
    "    async def __call__(self, request: starlette.requests.Request):\n",
    "        \"\"\"HTTP endpoint of the DAG.\"\"\"\n",
    "        input_data = await request.json()\n",
    "        return await self.predict(input_data)\n",
    "\n",
    "# DAG building\n",
    "with InputNode() as dag_input:\n",
    "    preprocessed_1 = preprocessor.bind(dag_input[0])  # Partial access of user input by index\n",
    "    preprocessed_2 = avg_preprocessor.bind(dag_input[1]) # Partial access of user input by index\n",
    "    m1 = Model.bind(1)\n",
    "    m2 = Model.bind(2)\n",
    "    combiner = Combiner.bind(m1, m2)\n",
    "    dag = combiner.run.bind(\n",
    "        preprocessed_1, preprocessed_2, dag_input[2]  # Partial access of user input by index\n",
    "    ) \n",
    "    # Each serve dag has a driver deployment as ingress that can be user provided.\n",
    "    serve_dag = DAGDriver.options(route_prefix=\"/my-dag\").bind(dag)\n",
    "\n",
    "\n",
    "dag_handle = serve.run(serve_dag)\n",
    "\n",
    "# Warm up\n",
    "ray.get(dag_handle.predict.remote([\"0\", [0, 0], \"sum\"]))\n",
    "\n",
    "# Python handle \n",
    "cur = time.time()\n",
    "print(ray.get(dag_handle.predict.remote([\"5\", [1, 2], \"sum\"])))\n",
    "print(f\"Time spent: {round(time.time() - cur, 2)} secs.\")\n",
    "# Http endpoint\n",
    "cur = time.time()\n",
    "print(requests.post(\"http://127.0.0.1:8000/my-dag\", json=[\"5\", [1, 2], \"sum\"]).text)\n",
    "print(f\"Time spent: {round(time.time() - cur, 2)} secs.\")\n",
    "\n",
    "# Python handle \n",
    "cur = time.time()\n",
    "print(ray.get(dag_handle.predict.remote([\"1\", [0, 2], \"max\"])))\n",
    "print(f\"Time spent: {round(time.time() - cur, 2)} secs.\")\n",
    "\n",
    "# Http endpoint\n",
    "cur = time.time()\n",
    "print(requests.post(\"http://127.0.0.1:8000/my-dag\", json=[\"1\", [0, 2], \"max\"]).text)\n",
    "print(f\"Time spent: {round(time.time() - cur, 2)} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4905c",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "```\n",
    "sum(['(1 * (5 + 1.5))', '(2 * (5 + 1.5))'])\n",
    "Time spent: 0.49 secs.\n",
    "sum(['(1 * (5 + 1.5))', '(2 * (5 + 1.5))'])\n",
    "Time spent: 0.49 secs.\n",
    "\n",
    "\n",
    "max(['(1 * (1 + 1.0))', '(2 * (1 + 1.0))'])\n",
    "Time spent: 0.48 secs.\n",
    "max(['(1 * (1 + 1.0))', '(2 * (1 + 1.0))'])\n",
    "Time spent: 0.48 secs.\n",
    "```\n",
    "\n",
    "\n",
    "Critical path for each request in the DAG is \n",
    "\n",
    "preprocessing: ```max(preprocessor, avg_preprocessor) = 0.15 secs```\n",
    "<br>\n",
    "model forward: ```max(m1.forward, m2.forward) = 0.3 secs```\n",
    "<br>\n",
    "<br>\n",
    "Total of `0.45` secs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6d861",
   "metadata": {},
   "source": [
    "## Key APIs Explained\n",
    "\n",
    "The class and function definition as well as decorator didn't diverage from existing serve API. So in the following section we only need to dive into a few new key APIs used: `bind()`, `InputNode()` and `serve.run()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f8a40",
   "metadata": {},
   "source": [
    "### **`bind(*args, **kwargs)`**\n",
    "\n",
    "Once called on supported ray decorated function or class (@ray.remote, @serve.deployment), generates an IR of type DAGNode that acts as the building block of graph building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ee63f",
   "metadata": {},
   "source": [
    "#### On function with no args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fecba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "def preprocessor():\n",
    "    print(\"hello\")\n",
    "\n",
    "# Produces a DeploymentFunctionNode with no bound args. \n",
    "func_node = preprocessor.bind()\n",
    "# All DAGNode types can be printed and shows its bound args as well as DAG structure based on \n",
    "print(func_node)\n",
    "dag_handle = serve.run(func_node)\n",
    "# Once executed it will execute and print \"hello\".\n",
    "print(ray.get(dag_handle.remote()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b2b87",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "```\n",
    "(DeploymentFunctionNode)(\n",
    "    body=<function my_func at 0x7fe8584ccc80>\n",
    "    args=[]\n",
    "    kwargs={}\n",
    "    options={}\n",
    "    other_args_to_resolve={\n",
    "        deployment_schema: name='preprocessor' import_path='dummpy.module' init_args=() init_kwargs={} num_replicas=1 route_prefix='/my_func' max_concurrent_queries=100 user_config=None autoscaling_config=None graceful_shutdown_wait_loop_s=2.0 graceful_shutdown_timeout_s=20.0 health_check_period_s=10.0 health_check_timeout_s=30.0 ray_actor_options=None\n",
    "        is_from_serve_deployment: True\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "```\n",
    "(my_func pid=15598) hello\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaad6f7",
   "metadata": {},
   "source": [
    "#### On function with args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2acaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "def preprocessor(val):\n",
    "    print(val)\n",
    "\n",
    "# Produces a DeploymentFunctionNode with no bound args.\n",
    "func_node = preprocessor.bind()\n",
    "\n",
    "dag_handle = serve.run(func_node)\n",
    "# Once executed it will execute with arg value of 2.\n",
    "print(ray.get(dag_handle.remote(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e022f",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "```\n",
    "(my_func pid=17060) 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c80f45",
   "metadata": {},
   "source": [
    "#### On class constructor \n",
    "\n",
    "**`Class.bind(*args, **kwargs)`** constructs and returns a DAGNode that acts as the instantiated instance of Class, where `*args` and `**kwargs` are used as init args.\n",
    "\n",
    "#### On class method\n",
    "\n",
    "Once a class is bound with its init args, its class methods can be directly accessed, called or bound with other args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfcf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class Model:\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    def get(self):\n",
    "        return self.val\n",
    "\n",
    "# Produces a deployment class node instance initialized with bound args value. \n",
    "class_node = Model.bind(5)\n",
    "print(class_node)\n",
    "dag_handle = serve.run(class_node)\n",
    "# Access get() class method on bound Model\n",
    "print(ray.get(dag_handle.get.remote()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed2dd2",
   "metadata": {},
   "source": [
    "#### Output\n",
    "```\n",
    "(DeploymentNode)(\n",
    "    body=<class '__main__.MyClass'>\n",
    "    args=[\n",
    "        5, \n",
    "    ]\n",
    "    kwargs={}\n",
    "    options={}\n",
    "    other_args_to_resolve={\n",
    "        deployment_schema: name='Model' import_path='dummpy.module' init_args=() init_kwargs={} num_replicas=1 route_prefix='/MyClass' max_concurrent_queries=100 user_config=None autoscaling_config=None graceful_shutdown_wait_loop_s=2.0 graceful_shutdown_timeout_s=20.0 health_check_period_s=10.0 health_check_timeout_s=30.0 ray_actor_options=None\n",
    "        is_from_serve_deployment: True\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "get() returns\n",
    "\n",
    "```\n",
    "5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da38d5d",
   "metadata": {},
   "source": [
    "### DAGNode as args in bind()\n",
    "\n",
    "DAGNode can also be passed into other DAGNode in dag binding. In the example above, ```Combiner``` calls into two instantiations of ```Model``` class, which can be bound and passed into ```Combiner```'s constructor as if we're passing in two regular python class instances.\n",
    "\n",
    "```\n",
    "m1 = Model.bind(1)\n",
    "m2 = Model.bind(2)\n",
    "combiner = Combiner.bind(m1, m2)\n",
    "```\n",
    "\n",
    "Similarly, we can also pass and bind upstream DAGNode results that will be resolved upon runtime to downstream DAGNodes, in our example, a `DeploymentMethodNode` that access class method of ```Combiner``` class takes two preprocessing DAGNodes' output as well as part of user input.\n",
    "\n",
    "```\n",
    "preprocessed_1 = preprocessor.bind(dag_input[0])\n",
    "preprocessed_2 = avg_preprocessor.bind(dag_input[1])\n",
    "...\n",
    "dag = combiner.run.bind(preprocessed_1, preprocessed_2, dag_input[2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b739396",
   "metadata": {},
   "source": [
    "### **```InputNode()```**\n",
    "\n",
    "```InputNode``` is a special singleton in DAG building that's only relevant to it's runtime call behavior. Even though all decorated classes or functions can be reused in arbitrary way to facilitate DAG building where the root DAGNode forms the graph with its children, in each deployment graph there should be one and only one InputNode used.\n",
    "\n",
    "```InputNode``` value is fulfilled and replaced by user input at runtime, therefore it takes no argument when being constructed.\n",
    "\n",
    "It's possible to access partial user input by index or key, if some DAGNode in the graph doesn't need the complete user input to run. In the example above, `combiner.run` only needs the element at index 2 to determine it's runtime behavior.\n",
    "\n",
    "```\n",
    "dag = combiner.run.bind(preprocessed_1, preprocessed_2, dag_input[2])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699e7fd",
   "metadata": {},
   "source": [
    "### Running Deployment Graph\n",
    "\n",
    "The deployment graph can be deployed with ```serve.run()```. ```serve.run()```\n",
    "takes in a target DeploymentNode, and it deploys the node's deployments, as\n",
    "well as all its child nodes' deployments. To deploy your graph, pass in the\n",
    "driver DeploymentNode into ```serve.run()```.\n",
    "\n",
    "Tip: You can also use the Serve CLI to run your deployment graph. The CLI was\n",
    "included with Serve when you did ``pip install \"ray[serve]\"``. The command\n",
    "```serve run [node import path]``` will deploy the node and its childrens'\n",
    "deployments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
